# -*- coding: utf-8 -*-
"""Submission 1 - NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a42n2W4KsTQyr__4v-4rd7TGHkbVtKig

# **Azhar Rizki Zulma**
## **Submission 1 - NLP**
Dataset: https://www.kaggle.com/lokkagle/movie-genre-data

### **Import Library**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

from google.colab import files

import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

"""### **Upload Dataset**"""

uploaded = files.upload()

"""### **Read Dataset**"""

df = pd.read_csv('kaggle_movie_train.csv')
print(f'Jumlah datasets: {len(df)}')
df.head()

"""### **Check Dataset Info & Nullable Value**"""

df.info()

"""### **Count Genre Dataset value**"""

df.genre.value_counts()

"""### **Data Splitting**
Memisahkan Dataset baru yang berisi genre dan sinopsis
"""

category = pd.get_dummies(df.genre)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(['id', 'genre'], axis=1)
df_baru

text = df_baru['text'].values
label = df_baru[['action', 'comedy',	'sci-fi', 'horror', 'drama', 'thriller', 'other', 'adventure', 'romance']].values

"""Memisahkan data train dan data test"""

text_train, text_test, label_train, label_test = train_test_split(text, label, test_size=0.2, random_state=42, shuffle = True)

"""### **Tokenizing, Sequencing, dan Padding**"""

tokenizer = Tokenizer(num_words=15000, oov_token='x', filters='!"#$%&()*+,-./:;<=>@[\]^_`{|}~ ')
tokenizer.fit_on_texts(text_train)
tokenizer.fit_on_texts(text_test)
 
sekuens_train = tokenizer.texts_to_sequences(text_train)
sekuens_test = tokenizer.texts_to_sequences(text_test)
 
padded_train = pad_sequences(sekuens_train) 
padded_test = pad_sequences(sekuens_test)

"""### **Permodelan Menggunakan Squential Model**"""

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=15000, output_dim=64),
    tf.keras.layers.LSTM(128, return_sequences=True),
    tf.keras.layers.GlobalMaxPooling1D(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(9, activation='softmax')
])

model.summary()

"""### **Callback**"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9 and logs.get('val_accuracy')>0.9):
      self.model.stop_training = True
      print("\nThe accuracy of the training set and the validation set has reached > 90%!")
callbacks = myCallback()

model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy',)

"""### **Training**"""

history = model.fit(padded_train, label_train, epochs=50,
                    validation_data=(padded_test, label_test), verbose=2, callbacks=[callbacks])

"""### **Evaluasi Model**"""

model.evaluate(padded_test, label_test)

"""### **Plot Accuracy & Loss**"""

loss = history.history['loss']
val_loss = history.history['val_loss']

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

plt.figure(figsize=(15, 5))

plt.subplot(1, 2, 1)
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.plot(loss, label='Training set')
plt.plot(val_loss, label='Validation set', linestyle='--')
plt.legend()
plt.grid(linestyle='--', linewidth=1, alpha=0.5)

plt.subplot(1, 2, 2)
plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.plot(acc, label='Training set')
plt.plot(val_acc, label='Validation set', linestyle='--')
plt.legend()
plt.grid(linestyle='--', linewidth=1, alpha=0.5)

plt.show()